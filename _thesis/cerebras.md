---
layout: page
title: "⚡ Implementation of Kernels and Benchmarking on the Cerebras Wafer-Scale Engine (WSE)"
description: 
img: https://plus.unsplash.com/premium_photo-1690297732590-b9875f77471d?q=80&w=3732&auto=format&fit=crop&ixlib=rb-4.0.3&ixid=M3wxMjA3fDB8MHxwaG90by1wYWdlfHx8fGVufDB8fHx8fA%3D%3D
importance: 1
category: Available Thesis
---

The Cerebras Wafer-Scale Engine (WSE) [1] is one of the most advanced hardware architectures designed specifically for accelerating machine learning workloads. It integrates a massive number of processing units on a single wafer, providing unprecedented computational power and memory bandwidth for training large-scale deep learning models. However, to fully utilize the potential of the WSE, it is necessary to optimize the implementation of machine learning kernels and benchmark them effectively.

In this thesis, the student will focus on implementing key machine learning kernels (e.g., matrix multiplication, convolutions, activation functions) for the Cerebras Wafer-Scale Engine (WSE) using simulation environments. The goal is to evaluate the performance of these kernels through simulations and explore optimization techniques that can improve the efficiency of computations on this unique architecture.

The student will be tasked with implementing and adapting algorithms for the WSE’s architecture and evaluating them through simulations, focusing on the performance impact, memory utilization, and scalability. The work will also include comparing the results against other state-of-the-art hardware accelerators (e.g., GPUs, TPUs) to identify potential areas for improvement. The thesis will involve using Cerebras’ simulation tools and APIs, and possibly working with real-world machine learning models for benchmarking.

**Skills required**:
- Familiarity with hardware accelerators and their programming models (GPUs, etc...)

[1] <a href="https://cerebras.ai/blog/cerebras-architecture-deep-dive-first-look-inside-the-hw/sw-co-design-for-deep-learning">Cerebras Architecture Deep Dive: First Look Inside the HW/SW Co-Design for Deep Learning</a><br>

<b>Approximate composition:</b> 20% State of the art analysis, 30% Theory/Design, 50% Implementation/Experiments  

<div class="row">
    <div class="col-sm mt-3 mt-md-0">
        {% include figure.html path="https://plus.unsplash.com/premium_photo-1690297732590-b9875f77471d?q=80&w=3732&auto=format&fit=crop&ixlib=rb-4.0.3&ixid=M3wxMjA3fDB8MHxwaG90by1wYWdlfHx8fGVufDB8fHx8fA%3D%3D" title="" class="img-fluid rounded z-depth-1" %}
    </div>
</div>
